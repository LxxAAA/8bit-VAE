{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NES-MDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to showcase a few things about the NES MDB and our work on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import pickle\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to showcase a few things about the NES MDB and our work on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Music Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by first loading the data. We apply a preprocessing step where we move all the notes so that there is no spacing between 0 and the rest of the integers. We remark that for P1 and P2, the note 32 is never played, so we ignore it and shift it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f3d5dcea572e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprocessed_songs\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0msong_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nesmdb24_seprsco/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mvoice_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnote_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f3d5dcea572e>\u001b[0m in \u001b[0;36mnote_counter\u001b[0;34m(songs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvoice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnote\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mvoice_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvoice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnote\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvoice_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def song_loader(folder):\n",
    "    processed_songs = []\n",
    "\n",
    "    #instrument info.\n",
    "    #(key,val) = (instrument, (note_size,velocity_size, timbre_size))\n",
    "    voices = {\"P1\": (77,16,4),\n",
    "                   \"P2\": (77,16,4),\n",
    "                   \"TR\": (89,0,0),\n",
    "                   \"NO\": (17,16,2)}\n",
    "\n",
    "    #First, we define the functions which will normalize our notes\n",
    "    #to begin at 0.\n",
    "\n",
    "    P1_normalizer = np.vectorize(lambda x : x - 32 if x > 0 else 0)\n",
    "    P2_normalizer = np.vectorize(lambda x : x - 32 if x > 0 else 0)\n",
    "    TR_normalizer = np.vectorize(lambda x : x - 20 if x > 0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "    for song in glob.glob(folder + '/*'):\n",
    "        with open(song, 'rb') as song_info:\n",
    "            rate, nsamps, exprsco = pickle.load(song_info)\n",
    "\n",
    "            #Normalize the notes for the voices.\n",
    "            exprsco[:,0] = P1_normalizer(exprsco[:,0])\n",
    "            exprsco[:,1] = P2_normalizer(exprsco[:,1])\n",
    "            exprsco[:,2] = TR_normalizer(exprsco[:,2])\n",
    "\n",
    "            processed_songs.append(exprsco)\n",
    "    \n",
    "    return processed_songs\n",
    "\n",
    "def note_counter(songs):\n",
    "    P1 = Counter()\n",
    "    P2 = Counter()\n",
    "    TR = Counter()\n",
    "    NO = Counter()\n",
    "    voice_counts = [P1,P2,TR,NO]\n",
    "\n",
    "    for song in processed_songs:\n",
    "        for voice in range(4):\n",
    "            for note in song[:,voice]:\n",
    "                voice_counts[voice][note] += 1\n",
    "    \n",
    "    return voice_counts\n",
    "\n",
    "processed_songs   = song_loader(folder = 'nesmdb24_seprsco/train')\n",
    "voice_counts = note_counter(processed_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by first preparing a function to count the number of times each notes appears for each instrument. As it turns out, the most popular note is \"0\" i.e. that the instrument is not playing. We will plot the counts for the all the notes per instrument in a moment, but we first want to emphasize just how often each voice is turned off. Most notably, notice that for the noise voice, 0 appears more than 50% of the time. It might even be worth considering removing it entirely for the dimension reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voices = [\"P1\",\"P2\",\"TR\",\"NO\"]\n",
    "tot_count = sum(voice_counts[0].values())\n",
    "\n",
    "for voice,note_count in zip(voices,voice_counts):\n",
    "    percentage = 100*note_count[0]/tot_count\n",
    "    print(voice + \" is turned off for {:.2f}% of the time.\".format(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_plotter(ax,voice_counts):\n",
    "    notes,counts = [],[]\n",
    "    for note, count in voice_counts.items():\n",
    "        notes.append(note)\n",
    "        counts.append(count)\n",
    "    max_note = max(notes)+1\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    #plt.xticks(np.arange(0, max_note, 1))\n",
    "    ax.hist(notes, weights= counts, bins=range(max_note))\n",
    "    ax.set_xlim(0,max_note-1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,7))\n",
    "fig.suptitle(\"Histograms for Pulses\",fontsize = 40)\n",
    "\n",
    "#First, we do voice P1.\n",
    "note_plotter(ax1,voice_counts[0])\n",
    "ax1.set_xlabel(\"Notes for P1\", fontsize=20)\n",
    "ax1.set_ylabel(\"Counts\", fontsize=20)\n",
    "ax1.set_ylim(0,600000)\n",
    "\n",
    "#Now voice P2\n",
    "note_plotter(ax2,voice_counts[1])\n",
    "ax2.set_xlabel(\"Notes for P2\", fontsize=20)\n",
    "ax2.set_ylim(0,600000)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "note_plotter(ax, voice_counts[2])\n",
    "ax.set_xlabel(\"Notes for TR\", fontsize=20)\n",
    "ax.set_ylabel(\"Counts\", fontsize=20)\n",
    "_ = ax.set_title(\"Histogram for TR voice\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "note_plotter(ax, voice_counts[3])\n",
    "ax.set_xlabel(\"Notes for NO\", fontsize=20)\n",
    "ax.set_ylabel(\"Counts\", fontsize=20)\n",
    "_ = ax.set_title(\"Histogram for NO voice\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frozen time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "j = 2\n",
    "voice_names = [\"P1\",\"P2\", \"TR\",\"NO\"]\n",
    "fig, ax = plt.subplots(figsize = (17,7))\n",
    "sns.barplot(x= [i for i in range(len(cnts[j]))], y = [len(Z) for Z in cnts[j]], ax = ax)\n",
    "ax.set_xlabel(\"Note range\", fontsize = 20)\n",
    "ax.set_ylabel(\"Count\", fontsize = 20)\n",
    "_ = ax.set_title(\"How many times did each \" + voice_names[j] +\" note get held?\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize = (15,7))\n",
    "sns.countplot(x=cnts[3][0], ax = ax2)\n",
    "ax2.set_title(\"Number of times the NO voice was turned off per duration.\", fontsize=20)\n",
    "ax2.set_xlabel(\"Number of timesteps held.\", fontsize= 20)\n",
    "ax2.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize = (15,7))\n",
    "sns.countplot(x=cnts[2][0], ax = ax2)\n",
    "ax2.set_title(\"Number of times the TR voice was turned off per duration.\", fontsize=20)\n",
    "ax2.set_xlabel(\"Number of timesteps held.\", fontsize= 20)\n",
    "ax2.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize = (15,7))\n",
    "sns.countplot(x=cnts[1][0], ax = ax2)\n",
    "ax2.set_title(\"Number of times the P2 voice was turned off per duration.\", fontsize=20)\n",
    "ax2.set_xlabel(\"Number of timesteps held.\", fontsize= 20)\n",
    "ax2.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(figsize = (15,7))\n",
    "sns.countplot(x=cnts[0][0], ax = ax2)\n",
    "ax2.set_title(\"Number of times the P1 voice was turned off per duration.\", fontsize=20)\n",
    "ax2.set_xlabel(\"Number of timesteps held.\", fontsize= 20)\n",
    "ax2.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Song Dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our preprocessing, we chopped the music into several pieces. In order to assign meaning to each piece, we created a dictionary which takes a song name and gives you all the pieces associated with that name. We leave it for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('52_12_TR_song_dict','rb') as file:\n",
    "    song_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133920,\n",
       " 133921,\n",
       " 133922,\n",
       " 133923,\n",
       " 133924,\n",
       " 133925,\n",
       " 133926,\n",
       " 133927,\n",
       " 133928,\n",
       " 133929,\n",
       " 133930,\n",
       " 133931,\n",
       " 133932,\n",
       " 133933,\n",
       " 133934,\n",
       " 133935,\n",
       " 133936,\n",
       " 133937,\n",
       " 133938,\n",
       " 133939,\n",
       " 133940,\n",
       " 133941,\n",
       " 133942,\n",
       " 133943,\n",
       " 133944,\n",
       " 133945,\n",
       " 133946,\n",
       " 133947,\n",
       " 133948,\n",
       " 133949,\n",
       " 133950,\n",
       " 133951,\n",
       " 133952,\n",
       " 133953,\n",
       " 133954,\n",
       " 133955,\n",
       " 133956,\n",
       " 133957,\n",
       " 133958,\n",
       " 133959,\n",
       " 133960,\n",
       " 133961,\n",
       " 133962,\n",
       " 133963,\n",
       " 133964,\n",
       " 133965,\n",
       " 133966,\n",
       " 133967,\n",
       " 133968,\n",
       " 133969,\n",
       " 133970,\n",
       " 133971,\n",
       " 133972,\n",
       " 133973,\n",
       " 133974,\n",
       " 133975,\n",
       " 133976,\n",
       " 133977,\n",
       " 133978,\n",
       " 133979,\n",
       " 133980]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#song_dict['nesmdb24_seprsco/train/380_WaronWheels_10_11ResultsTheme.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/221_MarioBros__01_02GameStartA.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/303_SpaceHarrier_11_12Hayaoh.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/346_TheJungleBook_04_05Level4Level7Level10.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/199_Labyrinth_MaounoMeikyu_08_09Oubliette.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/082_Dr_Mario_08_09Ending.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/105_FamicomJump_HeroRetsuden_06_07AdventureJumpWorld.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/117_FinalFantasy_11_12MenuScreen.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/053_ChoujinSentaiJetman_01_02AreaSelect.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/329_SwordMaster_06_07Stage3.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/025_BatmanReturns_03_04Opening1.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/032_BioSenshiDan_IncreasertonoTatakai_04_05Stage3.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/322_SuperMarioBros__02_03SwimmingAround.seprsco.pkl']\n",
    "#song_dict['nesmdb24_seprsco/train/106_FamicomMukashiBanashi_ShinOnigashima_05_06SecondChapterInsidetheHouseNight.seprsco.pkl']\n",
    "song_dict['nesmdb24_seprsco/train/042_CaptainTsubasaVol_II_SuperStriker_19_20FlamengoBeforeTheGame.seprsco.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[591037,\n",
       " 591038,\n",
       " 591039,\n",
       " 591040,\n",
       " 591041,\n",
       " 591042,\n",
       " 591043,\n",
       " 591044,\n",
       " 591045,\n",
       " 591046,\n",
       " 591047,\n",
       " 591048,\n",
       " 591049,\n",
       " 591050,\n",
       " 591051,\n",
       " 591052,\n",
       " 591053]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_dict['nesmdb24_seprsco/train/325_SuperMarioWorld_01_02YoshisIsland.seprsco.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(song, og_count, new_count, cpt_count):    \n",
    "    with open(song, 'rb') as song_info:\n",
    "        rate, nsamps, seprsco = pickle.load(song_info)\n",
    "    seprsco[:,3] = 0\n",
    "    normalized_score = song_normalizer(seprsco.copy(),'seprsco',False,None)\n",
    "    score, valid = new_scorer(normalized_score,77,32,True,True)\n",
    "    compact_score, valid = compactify_score(seprsco,77,32,True,True)\n",
    "    #og_count.append(score)\n",
    "    if not valid:\n",
    "        return\n",
    "    #new_score = postprocessing_sparse([score], None, True)[0]\n",
    "    #assert np.array_equal(new_score,seprsco)\n",
    "    og_count.append(seprsco.shape[0])\n",
    "    new_count.append(score.shape[0])\n",
    "    cpt_count.append(compact_score.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.431684255599976\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "folder = 'nesmdb24_seprsco/train'\n",
    "A,B,C = [],[],[]\n",
    "start = time.time()\n",
    "for i,song in enumerate(glob.glob(folder + '/*')):\n",
    "    process(song,A,B,C)\n",
    "print(time.time()-start)\n",
    "A,B,C = np.asarray(A), np.asarray(B), np.asarray(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690.6361471288701, 673.6229161153744, 1076.5800476316485)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), B.mean(), C.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41148451971421013"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(B>A).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5659bcd208>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(B-A, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_score(score, note_size, max_len, separate=True, TR=False):\n",
    "    \"\"\"\n",
    "    ----------------------------------------------------------------------------\n",
    "    This turns a piano_roll for a single voice into a sequence of events,\n",
    "    similar to Magenta's event decomposition. We count how many steps a note is\n",
    "    held, then turn into two events. The first event consists of a onehot version\n",
    "    of the note, and the other consists of onehot version of the number of steps\n",
    "    into the future.\n",
    "\n",
    "    Args:\n",
    "        score (np.array): Normalized score.\n",
    "        note_size (int): Number of notes per instrument, including off.\n",
    "        max_len (int): Maximum length allowed.\n",
    "        separate (bool): If True, separate P1 notes, P2 notes and time shift by\n",
    "        adding note_size.\n",
    "\n",
    "    Returns:\n",
    "        events (np.array): An array containing appropiate note values and counts,\n",
    "         with an offset by timesteps. Shape =(3, 2*timesteps+1)\n",
    "        lengths (np.array): An array containing lengths. Shape = (3,)\n",
    "    ----------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    events = []\n",
    "    voices = [\"P1\",\"P2\",\"TR\",\"NO\"]\n",
    "    timesteps = score.shape[0]\n",
    "    voices = 3 if TR else 2\n",
    "    lengths = []\n",
    "    score_length = score.shape[0]\n",
    "    last_notes = score[0]\n",
    "    max_count = 0\n",
    "    count = 0\n",
    "\n",
    "    #Compute offsets.\n",
    "    offset = 0\n",
    "    P2_offset = note_size\n",
    "    TR_offset = 2*note_size\n",
    "    cnt_offset = 2*note_size - 1 + (note_size + 12)\n",
    "    cnt_offset = cnt_offset if TR else 2*note_size -1\n",
    "    voice_offsets = [0,P2_offset, TR_offset]\n",
    "\n",
    "\n",
    "    events = [last_notes[i] + offset for i, offset in enumerate(voice_offsets[:voices])]\n",
    "    for notes in score:\n",
    "        #If same note, increase count.\n",
    "        if np.array_equal(notes,last_notes):\n",
    "            count += 1\n",
    "            #cur_count += 1\n",
    "            continue\n",
    "\n",
    "        events.append(cnt_offset + count + offset)\n",
    "        max_count = max(max_count,count)\n",
    "        count = 1\n",
    "\n",
    "        #events += [offset + notes[i] for i,offset in enumerate(voice_offsets[:voices])]\n",
    "        for i in range(3):\n",
    "            if last_notes[i] != notes[i]:\n",
    "                events.append(voice_offsets[i] + notes[i])\n",
    "        last_notes = notes\n",
    "\n",
    "        if max_count > max_len:\n",
    "            return (0,False)\n",
    "    max_count = max(count, max_count)\n",
    "    if max_count > max_len:\n",
    "        return (0,False)\n",
    "\n",
    "    events.append(cnt_offset + count + offset)\n",
    "    events = np.asarray(events).astype(np.int16)\n",
    "\n",
    "    return (events, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing_sparse(data, threshold, separate=True):\n",
    "    \n",
    "    P1_normalizer = lambda x : x + 32 if x > 0 else 0\n",
    "    P2_normalizer = lambda x : x + 32 if x > 0 else 0\n",
    "    TR_normalizer = lambda x : x + 20 if x > 0 else 0\n",
    "    #NO_normalizer = np.vectorize(lambda x : x)\n",
    "\n",
    "    normalizers = [P1_normalizer,P2_normalizer, TR_normalizer]\n",
    "\n",
    "    res = []\n",
    "    note_size = 108-32+1\n",
    "    offset = 0\n",
    "    P2_offset = note_size if separate else 0\n",
    "    TR_offset = 2*note_size if separate else 0\n",
    "    cnt_offset = 2*note_size - 1 + (note_size + 12) if separate else 0\n",
    "\n",
    "    for song in data:\n",
    "        notes = [[P1_normalizer(song[0]), P2_normalizer(song[1]-P2_offset), TR_normalizer(song[2]-TR_offset),0] for _ in range(song[3]-cnt_offset)]\n",
    "        last_notes = notes[-1][:]\n",
    "        new_notes = []\n",
    "        for event in song[4:]:\n",
    "            if event < P2_offset: #P1 pitch change.\n",
    "                last_notes[0] = P1_normalizer(event)\n",
    "            elif P2_offset <= event < TR_offset: #P2 pitch change\n",
    "                last_notes[1] = P2_normalizer(event - P2_offset)\n",
    "            elif TR_offset <= event <= cnt_offset: #TR pitch change\n",
    "                last_notes[2] = TR_normalizer(event - TR_offset)\n",
    "            else:\n",
    "                cnt = event - cnt_offset\n",
    "                assert cnt > 0, cnt\n",
    "                notes.extend([last_notes[:]]*cnt)\n",
    "\n",
    "        res.append(np.asarray([notes]))\n",
    "    \n",
    "    return np.vstack(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
